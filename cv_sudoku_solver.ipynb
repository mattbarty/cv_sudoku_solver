{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "import multiprocessing\n",
    "from tensorflow import keras\n",
    "from sudoku_solver import sudoku_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "    \n",
    "    # First Convolutional Block\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    # Third Convolutional Block (added for depth)\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    # Flatten and Fully Connected Layers\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(128, kernel_regularizer= tf.keras.regularizers.l2(l= 0.016), \n",
    "                          activity_regularizer= tf.keras.regularizers.l1(0.006),\n",
    "                          bias_regularizer= tf.keras.regularizers.l1(0.006), \n",
    "                          activation= 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(11, activation='softmax')\n",
    "])\n",
    "\n",
    "model.load_weights('sudoku2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzles = [os.path.join('puzzles', img) for img in os.listdir('./puzzles/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class SudokuDigitPredictor:\n",
    "\n",
    "    def __init__(self, model, confidence=0.9):\n",
    "        self.model = model\n",
    "        self.confidence = confidence\n",
    "        self.classes = [str(i) for i in range(11)]\n",
    "        \n",
    "    # def preprocess_squares_in_parallel(self, warped_sudoku):\n",
    "    #     with ThreadPoolExecutor(max_workers=4) as executor:  # adjust max_workers as needed\n",
    "    #         squares = list(executor.map(self.preprocess_for_prediction, [warped_sudoku[y_start:y_start + 28, x_start:x_start + 28] for i in range(9) for j in range(9, x_start=i*28, y_start=j*28)]))\n",
    "    #     return squares\n",
    "\n",
    "    def preprocess_for_prediction(self, square):\n",
    "        \"\"\"\n",
    "        Preprocess the cropped square for prediction.\n",
    "        This depends on how your model expects the input. \n",
    "        For example, rescaling, resizing, or reshaping might be necessary.\n",
    "        \"\"\"\n",
    "        # Ensure the square is in grayscale\n",
    "        if len(square.shape) == 3 and square.shape[2] == 3:\n",
    "            square = cv2.cvtColor(square, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        # Remove 10 pixels from all sides\n",
    "        square = square[3:-3, 3:-3]\n",
    "        # Apply binary threshold\n",
    "        _, binary = cv2.threshold(square, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Enhance contrast using histogram equalization\n",
    "        enhanced_binary = cv2.equalizeHist(binary)\n",
    "        \n",
    "        processed_square = cv2.resize(enhanced_binary, (28, 28))  # Resizing\n",
    "        processed_square = np.expand_dims(processed_square, axis=-1)  # Ensure it has a single channel\n",
    "        return processed_square\n",
    "\n",
    "    def predict_digits(self, warped_sudoku):\n",
    "        \"\"\"\n",
    "        Predicts digits for a given warped sudoku grid.\n",
    "        \"\"\"\n",
    "        squares = []\n",
    "        \n",
    "        # Crop the sudoku grid into 81 squares\n",
    "        for i in range(9):\n",
    "            for j in range(9):\n",
    "                x_start, y_start = i * 28, j * 28\n",
    "                square = warped_sudoku[x_start:x_start + 28, y_start:y_start + 28]\n",
    "                squares.append(self.preprocess_for_prediction(square))\n",
    "\n",
    "        # Convert list to numpy array for batch prediction\n",
    "        squares_np = np.stack(squares)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict_on_batch(squares_np)\n",
    "\n",
    "        max_confidences = np.amax(predictions, axis=1)\n",
    "        class_indices = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        # Ensure self.classes is a numpy array\n",
    "        class_array = np.array(self.classes)\n",
    "\n",
    "        # Determine where predictions exceed the confidence threshold\n",
    "        above_confidence = max_confidences > self.confidence\n",
    "\n",
    "        # Use boolean indexing to get relevant classes\n",
    "        relevant_classes = class_array[class_indices]\n",
    "\n",
    "        # Where predictions are above the confidence threshold, use predicted class, else '10'\n",
    "        predicted_classes = np.where(above_confidence, relevant_classes, '10').tolist()\n",
    "        \n",
    "        # Convert cell_values to integer-based numpy array, where '10' becomes 0\n",
    "        cell_values_int = np.array([0 if value == '10' else int(value) for value in predicted_classes])\n",
    "\n",
    "        # Reshape the numpy array to the desired 9x9 shape\n",
    "        grid = cell_values_int.reshape(9, 9)\n",
    "        \n",
    "        return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudokuGridHighlighter:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.last_contour = None\n",
    "        self.consistent_detections = 0\n",
    "        self.detection_threshold = 5\n",
    "        self.max_area_detected = 0\n",
    "        self.digit_predictor = SudokuDigitPredictor(model)\n",
    "        self.grid_prediction = None\n",
    "        self.sudoku_solution = None\n",
    "        self.frame_count = 0\n",
    "        self.predict_every_n_frames = 10\n",
    "        self.prev_frame = None\n",
    "\n",
    "    def frame_difference(self, current_frame, prev_frame):\n",
    "        \"\"\"\n",
    "        Compute the difference between current frame and previous frame.\n",
    "        This will be a simple method, but can be made more sophisticated.\n",
    "        \"\"\"\n",
    "        diff = cv2.absdiff(current_frame, prev_frame)\n",
    "        return np.average(diff)\n",
    "    \n",
    "    def preprocess(self, image):\n",
    "        \"\"\"Preprocess the image for contour detection.\"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (3, 3), 6)\n",
    "        return cv2.adaptiveThreshold(blur, 255, 1, 1, 11, 2)\n",
    "\n",
    "    def main_outline(self, contours):\n",
    "        \"\"\"Get the largest 4-sided contour in the image.\"\"\"\n",
    "        max_area = 0\n",
    "        biggest_contour = np.array([])\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            # Adjust the area threshold dynamically\n",
    "            if area > self.max_area_detected * 0.5 and area > max_area:\n",
    "                peri = cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "                \n",
    "                if len(approx) == 4:\n",
    "                    biggest_contour = approx\n",
    "                    max_area = area\n",
    "                        \n",
    "        return biggest_contour, max_area\n",
    "\n",
    "    def get_cropped_region(self, frame, padding=40):\n",
    "        \"\"\"Crops the frame based on the last detected contour and returns the cropped image and its offset.\"\"\"\n",
    "        if self.last_contour is None:\n",
    "            return frame, (0, 0)\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(self.last_contour)\n",
    "        x = max(0, x - padding)\n",
    "        y = max(0, y - padding)\n",
    "        w += 2 * padding\n",
    "        h += 2 * padding\n",
    "\n",
    "        return frame[y:y+h, x:x+w], (x, y)\n",
    "\n",
    "    def order_points(self, pts):\n",
    "        \"\"\"\n",
    "        Order the 4 points in this format: top-left, top-right, bottom-right, bottom-left\n",
    "        \"\"\"\n",
    "        rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "        s = pts.sum(axis=1)\n",
    "        rect[0] = pts[np.argmin(s)]  # top-left will have the smallest sum\n",
    "        rect[2] = pts[np.argmax(s)]  # bottom-right will have the largest sum\n",
    "\n",
    "        diff = np.diff(pts, axis=1)\n",
    "        rect[1] = pts[np.argmin(diff)]  # top-right will have the smallest difference\n",
    "        rect[3] = pts[np.argmax(diff)]  # bottom-left will have the largest difference\n",
    "\n",
    "        return rect\n",
    "\n",
    "    def warp_perspective(self, image, contour):\n",
    "        if contour.shape[0] != 4:\n",
    "            return None\n",
    "\n",
    "        ordered_contour = self.order_points(contour.reshape(4, 2))\n",
    "        src = np.array([\n",
    "            [0, 0],\n",
    "            [252 - 1, 0],\n",
    "            [252 - 1, 252 - 1],\n",
    "            [0, 252 - 1]\n",
    "        ], dtype=\"float32\")\n",
    "\n",
    "        matrix = cv2.getPerspectiveTransform(ordered_contour, src)\n",
    "        warped = cv2.warpPerspective(image, matrix, (252, 252))\n",
    "        return warped\n",
    "\n",
    "    \n",
    "    def check_sudoku_squares(self, warped_image):\n",
    "        count_valid_squares = 0\n",
    "\n",
    "        for i in range(9):\n",
    "            for j in range(9):\n",
    "                x_start, y_start = i * 28, j * 28\n",
    "                square = warped_image[y_start:y_start + 28, x_start:x_start + 28]\n",
    "                edges = cv2.Canny(square, 50, 150, apertureSize=3)\n",
    "                lines = cv2.HoughLines(edges, 1, np.pi / 180, 15)\n",
    "                \n",
    "                if lines is not None:\n",
    "                    count_valid_squares += 1\n",
    "\n",
    "        return count_valid_squares\n",
    "    \n",
    "    def _solve_sudoku(self, grid):\n",
    "        def is_valid_move(x, y, val, grid):\n",
    "            \"\"\"Check if placing val at grid[x][y] is valid.\"\"\"\n",
    "            \n",
    "            # Check row and column\n",
    "            for i in range(9):\n",
    "                if grid[x][i] == val or grid[i][y] == val:\n",
    "                    return False\n",
    "                    \n",
    "            # Check 3x3 box\n",
    "            startRow, startCol = 3 * (x // 3), 3 * (y // 3)\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    if grid[i + startRow][j + startCol] == val:\n",
    "                        return False\n",
    "                        \n",
    "            return True\n",
    "\n",
    "        def _solve_sudoku_helper(grid_copy):\n",
    "            \"\"\"Helper function for solve_sudoku.\"\"\"\n",
    "            \n",
    "            for x in range(9):\n",
    "                for y in range(9):\n",
    "                    if grid_copy[x][y] == 0:\n",
    "                        for val in range(1, 10):\n",
    "                            if is_valid_move(x, y, val, grid_copy):\n",
    "                                grid_copy[x][y] = val\n",
    "                                if _solve_sudoku_helper(grid_copy):\n",
    "                                    return True\n",
    "                                grid_copy[x][y] = 0\n",
    "                        return False\n",
    "            return True\n",
    "\n",
    "        \"\"\"Fill the grid using backtracking and return a solved copy.\"\"\"\n",
    "            \n",
    "        # Create a deep copy of the original grid\n",
    "        grid_copy = np.copy(grid)\n",
    "        \n",
    "        if _solve_sudoku_helper(grid_copy):\n",
    "            return grid_copy\n",
    "        return None  # Return None if the grid couldn't be solved\n",
    "    \n",
    "    def solve_sudoku_timed(self, grid, timeout=0.5):\n",
    "        \"\"\"\n",
    "        Attempt to solve the Sudoku with a time limit.\n",
    "        If the Sudoku is solved within the time limit, return the solution.\n",
    "        If not, return None.\n",
    "        \"\"\"\n",
    "        result = {\"solution\": None}\n",
    "        \n",
    "        def worker():\n",
    "            solution = self._solve_sudoku(grid)\n",
    "            result[\"solution\"] = solution\n",
    "\n",
    "        t = threading.Thread(target=worker)\n",
    "        t.start()\n",
    "        t.join(timeout=timeout)  # half a second time limit\n",
    "        \n",
    "        if t.is_alive():  # if thread is still running after 0.5 seconds\n",
    "            # Optionally, you might want to log or indicate that solving was terminated due to time constraints\n",
    "            return None  # or an indication of failure if you prefer\n",
    "        \n",
    "        return result[\"solution\"]\n",
    "    \n",
    "    def get_perspective_matrices(self, contour):\n",
    "        if contour.shape[0] != 4:\n",
    "            return None, None\n",
    "\n",
    "        ordered_contour = self.order_points(contour.reshape(4, 2))\n",
    "        src = np.array([\n",
    "            [0, 0],\n",
    "            [252 - 1, 0],\n",
    "            [252 - 1, 252 - 1],\n",
    "            [0, 252 - 1]\n",
    "        ], dtype=\"float32\")\n",
    "\n",
    "        matrix = cv2.getPerspectiveTransform(ordered_contour, src)\n",
    "        inverse_matrix = cv2.getPerspectiveTransform(src, ordered_contour)\n",
    "        return matrix, inverse_matrix\n",
    " \n",
    " \n",
    "    def overlay_solved_digits(self, image, solution, original_grid, inverse_matrix):\n",
    "        \n",
    "        height, width = image.shape[0:2]\n",
    "        \n",
    "        # Dimensions of each cell\n",
    "        cell_width = width // 9\n",
    "        cell_height = height // 9\n",
    "        \n",
    "        font_scale = min(cell_width, cell_height) / 40\n",
    "        \n",
    "        for i in range(9):\n",
    "            for j in range(9):\n",
    "                if original_grid[i][j] == 0 and solution[i][j] != 0:  # Check if the cell was empty\n",
    "                    x_center, y_center = (j + 0.5) * 28, (i + 0.5) * 28\n",
    "                    pt = np.array([[[x_center, y_center]]], dtype=\"float32\")\n",
    "                    unwarp_pt = cv2.perspectiveTransform(pt, inverse_matrix)[0][0]\n",
    "                    \n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    cv2.putText(image, str(solution[i][j]), (int(unwarp_pt[0]), int(unwarp_pt[1])),\n",
    "                                font, font_scale, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    def detect_and_highlight_grid(self, image):\n",
    "        \"\"\"Detects the Sudoku grid and highlights it.\"\"\"\n",
    "        cropped_image, (offset_x, offset_y) = self.get_cropped_region(image)\n",
    "\n",
    "        preprocessed_image = self.preprocess(cropped_image)\n",
    "        contours, _ = cv2.findContours(preprocessed_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        biggest_contour, max_area = self.main_outline(contours)\n",
    "        \n",
    "        warped = self.warp_perspective(cropped_image, biggest_contour)\n",
    "        matrix, inverse_matrix = self.get_perspective_matrices(biggest_contour)\n",
    "\n",
    "        if warped is None:\n",
    "            self.consistent_detections -= 1\n",
    "            if self.consistent_detections < -3:\n",
    "                self.last_contour = None\n",
    "                self.consistent_detections = 0\n",
    "            return image\n",
    "\n",
    "        valid_squares = self.check_sudoku_squares(warped)\n",
    "        \n",
    "        if valid_squares > 81 * 0.75:\n",
    "            if biggest_contour.size != 0:\n",
    "                biggest_contour += np.array([offset_x, offset_y]).reshape(1, 1, 2)\n",
    "\n",
    "            if max_area > self.max_area_detected:\n",
    "                self.max_area_detected = max_area\n",
    "\n",
    "            cv2.drawContours(image, [biggest_contour], 0, (255, 105, 180), 6)\n",
    "            self.consistent_detections += 1\n",
    "\n",
    "            if self.consistent_detections > self.detection_threshold:\n",
    "                self.last_contour = biggest_contour\n",
    "\n",
    "            # Resizing the warped Sudoku grid to display on the main image\n",
    "            grid_display_size = (100, 100)  # Adjust size as per your requirements\n",
    "            small_grid = cv2.resize(warped, grid_display_size)\n",
    "\n",
    "            # Positioning the warped grid on the bottom right corner of the main image\n",
    "            image[-grid_display_size[1]:, -grid_display_size[0]:] = small_grid\n",
    "\n",
    "        else:\n",
    "            self.consistent_detections -= 1\n",
    "            if self.consistent_detections < -3:\n",
    "                self.last_contour = None\n",
    "                self.consistent_detections = 0\n",
    "                \n",
    "        # Reducing number of predictions\n",
    "        if self.frame_count % self.predict_every_n_frames == 0:\n",
    "            if self.prev_frame is not None:\n",
    "                diff = self.frame_difference(image, self.prev_frame)\n",
    "                \n",
    "                if diff > 10:\n",
    "                    self.grid_prediction = self.digit_predictor.predict_digits(warped)\n",
    "                    # Use the timed solver here\n",
    "                    solved_grid = self.solve_sudoku_timed(self.grid_prediction)\n",
    "                    if solved_grid is not None:\n",
    "                        self.sudoku_solution = solved_grid\n",
    "            else:\n",
    "                self.grid_prediction = self.digit_predictor.predict_digits(warped)\n",
    "                # And here\n",
    "                solved_grid = self.solve_sudoku_timed(self.grid_prediction)\n",
    "                if solved_grid is not None:\n",
    "                    self.sudoku_solution = solved_grid\n",
    "\n",
    "        if self.sudoku_solution is not None:\n",
    "            image = self.overlay_solved_digits(image, self.sudoku_solution, self.grid_prediction, inverse_matrix)\n",
    "\n",
    "        self.frame_count += 1\n",
    "        self.prev_frame = image.copy()\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlighter = SudokuGridHighlighter()\n",
    "\n",
    "puzzles = [os.path.join('puzzles', img) for img in os.listdir('./puzzles/')]\n",
    "highlighted_frame = highlighter.detect_and_highlight_grid(cv2.imread(puzzles[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3829995992312325\n",
      "4.004613961145357\n",
      "3.2406956880823325\n",
      "3.0728456741329224\n",
      "3.4894871543646153\n",
      "3.0413688578311544\n",
      "2.877049511549226\n",
      "2.9960094723137423\n",
      "3.1119292089577355\n",
      "3.13866308742516\n",
      "6.729826357521167\n",
      "14.887268561572254\n",
      "18.03196532243065\n",
      "14.952276687657207\n",
      "15.728203216335423\n",
      "8.06683206681546\n",
      "5.715045656640805\n",
      "17.27433618521274\n",
      "10.068685899139123\n",
      "10.348084142620541\n",
      "5.206846088186842\n",
      "10.820685314592412\n"
     ]
    }
   ],
   "source": [
    "def webcam_feed():\n",
    "    highlighter = SudokuGridHighlighter()\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    video_capture.set(cv2.CAP_PROP_FPS, 30)\n",
    "    \n",
    "    # Set resolution\n",
    "    video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 128)\n",
    "    video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 128)\n",
    "\n",
    "    if not video_capture.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        highlighted_frame = highlighter.detect_and_highlight_grid(frame)\n",
    "        cv2.imshow('Webcam Feed - Sudoku Grid Highlighter', highlighted_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    webcam_feed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "class SudokuSolver:\n",
    "    def __init__(self, model, confidence=0.9):\n",
    "        self.model = model\n",
    "        self.confidence = confidence\n",
    "        self.classes = [str(i) for i in range(11)]\n",
    "        self.solve_cooldown = 0\n",
    "        self.solved_grid = None\n",
    "        self.grid = None\n",
    "        self.grid_detected_last_frame = False  # Track if the grid was detected in the last frame\n",
    "    \n",
    "    @staticmethod\n",
    "    def timer_decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start_time = time.time()\n",
    "            result = func(*args, **kwargs)\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            print(f\"'{func.__name__}' took {elapsed_time:.6f} seconds to run.\")\n",
    "            return result\n",
    "        return wrapper\n",
    "\n",
    "    # @timer_decorator\n",
    "    def preprocess(self, image):\n",
    "        \"\"\"Preprocess the image for contour detection.\"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (3, 3), 6)\n",
    "        return cv2.adaptiveThreshold(blur, 255, 1, 1, 11, 2)\n",
    "\n",
    "    # @timer_decorator\n",
    "    def main_outline(self, contours):\n",
    "        \"\"\"Get the largest 4-sided contour in the image.\"\"\"\n",
    "        max_area = 0\n",
    "        biggest_contour = np.array([])\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 50:\n",
    "                peri = cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "                \n",
    "                if len(approx) == 4 and area > max_area:\n",
    "                    biggest_contour = approx\n",
    "                    max_area = area\n",
    "                    \n",
    "        return biggest_contour, max_area\n",
    "\n",
    "    # @timer_decorator\n",
    "    def reframe(self, points):\n",
    "        \"\"\"Re-order points to top-left, top-right, bottom-left, bottom-right.\"\"\"\n",
    "        points = points.reshape((4, 2))\n",
    "        sorted_points = np.zeros((4, 1, 2), dtype=np.int32)\n",
    "        \n",
    "        add = points.sum(1)\n",
    "        diff = np.diff(points, axis=1)\n",
    "        \n",
    "        sorted_points[0], sorted_points[3] = points[np.argmin(add)], points[np.argmax(add)]\n",
    "        sorted_points[1], sorted_points[2] = points[np.argmin(diff)], points[np.argmax(diff)]\n",
    "        \n",
    "        return sorted_points\n",
    "\n",
    "    # @timer_decorator\n",
    "    def splitcells(self, img):\n",
    "        \"\"\"Split image into 81 cells.\"\"\"\n",
    "        return [box for row in np.vsplit(img, 9) for box in np.hsplit(row, 9)]\n",
    "    \n",
    "    # @timer_decorator\n",
    "    def CropCell(self, cells):\n",
    "        \"\"\"Crop each cell to remove 10 pixels from each side and convert to binary.\"\"\"\n",
    "        binary_cells = []\n",
    "        for cell in cells:\n",
    "            cropped = cell[5:-5, 5:-5]\n",
    "            \n",
    "            # Convert to grayscale if it's not already\n",
    "            if len(cropped.shape) == 3 and cropped.shape[2] == 3:\n",
    "                cropped = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Apply binary threshold\n",
    "            _, binary = cv2.threshold(cropped, 127, 255, cv2.THRESH_BINARY)\n",
    "            enhanced_binary = self.enhance_contrast(binary)\n",
    "            binary_cells.append(Image.fromarray(enhanced_binary))\n",
    "        \n",
    "        return binary_cells\n",
    "\n",
    "    # @timer_decorator\n",
    "    def predict_sudoku_cells(self, cells):\n",
    "        batch_data = []\n",
    "        for cell in cells:\n",
    "            im = tf.keras.preprocessing.image.img_to_array(cell)\n",
    "            im = cv2.resize(im, (28, 28))\n",
    "            im = np.expand_dims(im, axis=-1)\n",
    "            batch_data.append(im)\n",
    "        batch_data = np.stack(batch_data, axis=0)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict_on_batch(batch_data)\n",
    "        \n",
    "        max_confidences = np.amax(predictions, axis=1)\n",
    "        class_indices = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        # Ensure self.classes is a numpy array\n",
    "        class_array = np.array(self.classes)\n",
    "\n",
    "        # Determine where predictions exceed the confidence threshold\n",
    "        above_confidence = max_confidences > self.confidence\n",
    "\n",
    "        # Use boolean indexing to get relevant classes\n",
    "        relevant_classes = class_array[class_indices]\n",
    "\n",
    "        # Where predictions are above the confidence threshold, use predicted class, else '10'\n",
    "        predicted_classes = np.where(above_confidence, relevant_classes, '10').tolist()\n",
    "\n",
    "        return predicted_classes\n",
    "\n",
    "    # @timer_decorator\n",
    "    def overlay_solution_on_image(self, image, grid, original_grid):\n",
    "        \"\"\"\n",
    "        Overlay the solved numbers on the original Sudoku image.\n",
    "\n",
    "        Parameters:\n",
    "        - image: The original Sudoku image.\n",
    "        - grid: The solved Sudoku grid.\n",
    "        - original_grid: The transcribed Sudoku grid from the image.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert grayscale to BGR if image has only one channel\n",
    "        if len(image.shape) == 2 or image.shape[2] == 1:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Dimensions of the image\n",
    "        height, width = image.shape[0:2]\n",
    "\n",
    "        # Dimensions of each cell\n",
    "        cell_width = width // 9\n",
    "        cell_height = height // 9\n",
    "\n",
    "        # Set appropriate font scale and thickness considering the size of the cells\n",
    "        font_scale = min(cell_width, cell_height) / 40  # Adjust the denominator as needed\n",
    "        thickness = int(font_scale) * 2\n",
    "\n",
    "        for x in range(9):\n",
    "            for y in range(9):\n",
    "                if original_grid[x][y] == 0:  # If the cell was originally empty\n",
    "                    cell_value = str(grid[x][y])\n",
    "\n",
    "                    # Calculate text size\n",
    "                    (text_width, text_height), _ = cv2.getTextSize(cell_value, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)\n",
    "\n",
    "                    # Determine the position to put the text (approximately in the center of the cell)\n",
    "                    pos = (y * cell_width + (cell_width - text_width) // 2, \n",
    "                        x * cell_height + (cell_height + text_height) // 2)\n",
    "\n",
    "                    # Overlay the text on the copied image\n",
    "                    cv2.putText(image, cell_value, pos, cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 105, 180), thickness)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    # @timer_decorator\n",
    "    def solve_sudoku(self, grid):\n",
    "        def is_valid_move(x, y, val, grid):\n",
    "            \"\"\"Check if placing val at grid[x][y] is valid.\"\"\"\n",
    "            \n",
    "            # Check row and column\n",
    "            for i in range(9):\n",
    "                if grid[x][i] == val or grid[i][y] == val:\n",
    "                    return False\n",
    "                    \n",
    "            # Check 3x3 box\n",
    "            startRow, startCol = 3 * (x // 3), 3 * (y // 3)\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    if grid[i + startRow][j + startCol] == val:\n",
    "                        return False\n",
    "                        \n",
    "            return True\n",
    "\n",
    "        def _solve_sudoku_helper(grid_copy):\n",
    "            \"\"\"Helper function for solve_sudoku.\"\"\"\n",
    "            \n",
    "            for x in range(9):\n",
    "                for y in range(9):\n",
    "                    if grid_copy[x][y] == 0:\n",
    "                        for val in range(1, 10):\n",
    "                            if is_valid_move(x, y, val, grid_copy):\n",
    "                                grid_copy[x][y] = val\n",
    "                                if _solve_sudoku_helper(grid_copy):\n",
    "                                    return True\n",
    "                                grid_copy[x][y] = 0\n",
    "                        return False\n",
    "            return True\n",
    "\n",
    "        \"\"\"Fill the grid using backtracking and return a solved copy.\"\"\"\n",
    "            \n",
    "        # Create a deep copy of the original grid\n",
    "        grid_copy = np.copy(grid)\n",
    "        \n",
    "        if _solve_sudoku_helper(grid_copy):\n",
    "            return grid_copy\n",
    "        return None  # Return None if the grid couldn't be solved\n",
    "    \n",
    "    # @timer_decorator\n",
    "    def solve_sudoku_with_timeout(self, grid, timeout=0.005):\n",
    "        result = [None] # Use a list to store the result since lists are mutable\n",
    "        solved_event = threading.Event() # Event flag to signal when the solving is done\n",
    "\n",
    "        def worker():\n",
    "            result[0] = self.solve_sudoku(grid)\n",
    "            solved_event.set()  # Signal that the solving is done\n",
    "\n",
    "        thread = threading.Thread(target=worker)\n",
    "        thread.start()\n",
    "        solved_event.wait(timeout=timeout)\n",
    "\n",
    "        if thread.is_alive():\n",
    "            # Stop the thread if it's still running (not recommended in real applications)\n",
    "            # Ideally, you would let the thread finish its work in the background\n",
    "            # If you really need to stop threads, consider using multiprocessing instead\n",
    "            print(\"Solver took too long!\")\n",
    "            return None\n",
    "\n",
    "        return result[0]\n",
    "    \n",
    "    # @timer_decorator\n",
    "    def inverse_transform_and_overlay(self, overlayed_image, original_image, matrix):\n",
    "        \"\"\"Inverse transform the overlayed_image and overlay on original image.\"\"\"\n",
    "        inversed = cv2.warpPerspective(overlayed_image, np.linalg.inv(matrix), (original_image.shape[1], original_image.shape[0]))\n",
    "        mask = cv2.warpPerspective(np.ones_like(overlayed_image) * 255, np.linalg.inv(matrix), (original_image.shape[1], original_image.shape[0]))\n",
    "        \n",
    "        # Apply mask to original image to black out the Sudoku area\n",
    "        masked_original = cv2.bitwise_and(original_image, 255 - mask)\n",
    "\n",
    "        # Combine the masked original image with the inversed transformed image\n",
    "        combined = cv2.bitwise_or(masked_original, inversed)\n",
    "\n",
    "        return combined\n",
    "\n",
    "    @staticmethod\n",
    "    def get_side_lengths(points):\n",
    "        \"\"\"Return lengths of sides of the quadrilateral defined by points.\"\"\"\n",
    "        p = points.reshape(4, 2)\n",
    "        lengths = [\n",
    "            np.linalg.norm(p[0] - p[1]),\n",
    "            np.linalg.norm(p[1] - p[2]),\n",
    "            np.linalg.norm(p[2] - p[3]),\n",
    "            np.linalg.norm(p[3] - p[0])\n",
    "        ]\n",
    "        return lengths\n",
    "    \n",
    "    # @timer_decorator\n",
    "    def enhance_contrast(self, cell):\n",
    "        \"\"\"Enhance the contrast of the image using histogram equalization.\"\"\"\n",
    "        equalized = cv2.equalizeHist(cell)\n",
    "        return equalized\n",
    "\n",
    "    # @timer_decorator\n",
    "    def warp_grid_to_standard(self, img):\n",
    "            \"\"\"Warp the grid such that it aligns perfectly with the standard grid lines.\"\"\"\n",
    "            target_points = np.array([\n",
    "                [0, 0],\n",
    "                [449, 0],\n",
    "                [449, 449],\n",
    "                [0, 449]\n",
    "            ], dtype=np.float32)\n",
    "\n",
    "            h, w = img.shape[:2]\n",
    "            src_points = np.array([\n",
    "                [0, 0],\n",
    "                [w-1, 0],\n",
    "                [w-1, h-1],\n",
    "                [0, h-1]\n",
    "            ], dtype=np.float32)\n",
    "            \n",
    "            matrix = cv2.getPerspectiveTransform(src_points, target_points)\n",
    "            aligned_img = cv2.warpPerspective(img, matrix, (450, 450))\n",
    "            return aligned_img\n",
    "\n",
    "    # @timer_decorator\n",
    "    def _find_grid_lines(self, image):\n",
    "        threshold = self.preprocess(image)\n",
    "        contour, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        biggest, _ = self.main_outline(contour)\n",
    "        \n",
    "        if biggest.size != 0:\n",
    "            biggest = self.reframe(biggest)\n",
    "            \n",
    "            # If a grid was detected in the last frame, compare side lengths\n",
    "            if self.grid_detected_last_frame:\n",
    "                previous_lengths = self.get_side_lengths(self.last_detected_grid)\n",
    "                current_lengths = self.get_side_lengths(biggest)\n",
    "                diff = np.abs(np.array(previous_lengths) - np.array(current_lengths))\n",
    "                if np.any(diff > 300):\n",
    "                    print(diff)\n",
    "                    print(\"Grid is too different from the last frame, skipping this frame.\")\n",
    "                    return (None, None)\n",
    "                    \n",
    "            # Store this grid for comparison in the next frame\n",
    "            self.last_detected_grid = biggest\n",
    "            \n",
    "            pts1 = np.float32(biggest)\n",
    "            pts2 = np.float32([[0,0],[450,0],[0,450],[450,450]])\n",
    "            matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "            if np.linalg.det(matrix) == 0:\n",
    "                # Matrix is singular and can't be inverted\n",
    "                print(\"Singular matrix detected, skipping this frame.\")\n",
    "                return (None, None)\n",
    "        \n",
    "            imagewrap = cv2.warpPerspective(image, matrix, (450,450))\n",
    "            imagewrap = cv2.cvtColor(imagewrap, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Warp the grid to make it standard\n",
    "            imagewrap = self.warp_grid_to_standard(imagewrap)\n",
    "            \n",
    "            if imagewrap is None:\n",
    "                self.grid_detected_last_frame = False\n",
    "            else:\n",
    "                self.grid_detected_last_frame = True\n",
    "                \n",
    "            return (imagewrap, matrix)\n",
    "        else:\n",
    "            return (None, None)\n",
    "    \n",
    "    def solve(self, image, frame_count):\n",
    "        # Only run the solver logic every 5 frames\n",
    "        if frame_count % 5 == 0:\n",
    "            if self.solve_cooldown > 0:\n",
    "                self.solve_cooldown -= 1\n",
    "                print(f'cooldown: {self.solve_cooldown}')\n",
    "\n",
    "            # look for grid lines\n",
    "            imagewrap, matrix = self._find_grid_lines(image)\n",
    "            \n",
    "            # Check if grid was detected in this frame but not in the last frame\n",
    "            grid_just_detected = imagewrap is not None and not self.grid_detected_last_frame\n",
    "            \n",
    "            if imagewrap is None:\n",
    "                return image\n",
    "\n",
    "            if (frame_count % 10 == 0 and self.solve_cooldown == 0) or grid_just_detected:\n",
    "                start_time = time.time()\n",
    "                # Reset cooldown\n",
    "                self.solve_cooldown = 15\n",
    "                self.solved_sudoku = None\n",
    "                self.grid = None\n",
    "                self.frame_count = 0\n",
    "\n",
    "                cells = self.splitcells(imagewrap)\n",
    "                self.cells_cropped = self.CropCell(cells)\n",
    "\n",
    "                # Using batch prediction\n",
    "                cell_values = self.predict_sudoku_cells(self.cells_cropped)\n",
    "                \n",
    "                # Convert cell_values to integer-based numpy array, where '10' becomes 0\n",
    "                cell_values_int = np.array([0 if value == '10' else int(value) for value in cell_values])\n",
    "\n",
    "                # Reshape the numpy array to the desired 9x9 shape\n",
    "                self.grid = cell_values_int.reshape(9, 9)\n",
    "\n",
    "                # Instead of solving directly, use ThreadPoolExecutor\n",
    "                with ThreadPoolExecutor() as executor:\n",
    "                    future = executor.submit(self.solve_sudoku_with_timeout, self.grid)\n",
    "                    self.solved_grid = future.result()\n",
    "                    \n",
    "                if self.solved_grid is not None:\n",
    "                    print('solved!')\n",
    "                    print(self.solved_grid)\n",
    "                    end_time = time.time()\n",
    "                    print(f\"Time taken for solve: {end_time - start_time} seconds\")\n",
    "\n",
    "    \n",
    "    def overlay(self, image):\n",
    "        start_time = time.time()\n",
    "        if self.solved_grid is None or self.grid is None:\n",
    "            return image\n",
    "\n",
    "        # look for grid lines\n",
    "        imagewrap, matrix = self._find_grid_lines(image)\n",
    "        if imagewrap is None:\n",
    "            return image\n",
    "        \n",
    "        overlayed_image = self.overlay_solution_on_image(imagewrap, self.solved_grid, self.grid)\n",
    "        combined_image = self.inverse_transform_and_overlay(overlayed_image, image, matrix)\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken for overlay function: {end_time - start_time} seconds\")\n",
    "        return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = SudokuSolver(model, confidence=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzles = [os.path.join('puzzles', img) for img in os.listdir('./puzzles/')]\n",
    "solved_sudoku = solver.solve(cv2.imread(puzzles[0]), frame_count=10)\n",
    "overlayed_frame = solver.overlay(cv2.imread(puzzles[0]))\n",
    "plt.imshow(overlayed_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webcam_sudoku_solver(model):\n",
    "    # Initialize the webcam\n",
    "    cap = cv2.VideoCapture(0)  # Use 0 for default webcam\n",
    "    cap.set(cv2.CAP_PROP_FPS, 10)\n",
    "    \n",
    "    # Set resolution\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 64)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 64)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Couldn't open the webcam.\")\n",
    "        return\n",
    "    \n",
    "    # Create an instance of the SudokuSolver\n",
    "    sudoku_solver = SudokuSolver(model)\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        frame_count += 1\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        sudoku_solver.solve(frame, frame_count)\n",
    "        overlayed_frame = sudoku_solver.overlay(frame)\n",
    "        \n",
    "        cv2.imshow('Webcam Sudoku Solver', overlayed_frame)\n",
    "        \n",
    "        # Press 'q' to exit the loop and close the webcam feed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the webcam and destroy all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Placeholder for your trained model\n",
    "webcam_sudoku_solver(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webcam_feed():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 15)\n",
    "\n",
    "    frame_skip = 10  # process every 10th frame\n",
    "    frame_count = 0\n",
    "\n",
    "    # Instantiate the solver once here\n",
    "    solver = SudokuSolver(model)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "        frame_count += 1\n",
    "        if frame_count % frame_skip == 0:\n",
    "            # Pass the frame to the existing solver instance\n",
    "            solved_frame = solver.solve_frame(frame)\n",
    "\n",
    "            if solved_frame is not None:\n",
    "                cv2.imshow('Sudoku Solver', solved_frame)\n",
    "            else:\n",
    "                cv2.imshow('Sudoku Solver', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "webcam_feed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(puzzles[0])\n",
    "height, width = 480, 480  # example dimensions\n",
    "resized_image = cv2.resize(image, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "plt.imshow(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "for contour in contours:\n",
    "    if len(cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)) == 4:\n",
    "        grid_contour = contour\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "rect = order_points(grid_contour.reshape(4, 2))\n",
    "(topLeft, topRight, bottomRight, bottomLeft) = rect\n",
    "maxWidth = max(int(cv2.norm(bottomRight, bottomLeft)), int(cv2.norm(topRight, topLeft)))\n",
    "maxHeight = max(int(cv2.norm(topRight, bottomRight)), int(cv2.norm(topLeft, bottomLeft)))\n",
    "dst = np.array([[0, 0], [maxWidth - 1, 0], [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype=\"float32\")\n",
    "transformMatrix = cv2.getPerspectiveTransform(rect, dst)\n",
    "warp = cv2.warpPerspective(resized_image, transformMatrix, (maxWidth, maxHeight))\n",
    "\n",
    "\n",
    "plt.imshow(warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
