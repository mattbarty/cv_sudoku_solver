{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "import multiprocessing\n",
    "from tensorflow import keras\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "    \n",
    "    # First Convolutional Block\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    # Third Convolutional Block (added for depth)\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    # Flatten and Fully Connected Layers\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(128, kernel_regularizer= tf.keras.regularizers.l2(l= 0.016), \n",
    "                          activity_regularizer= tf.keras.regularizers.l1(0.006),\n",
    "                          bias_regularizer= tf.keras.regularizers.l1(0.006), \n",
    "                          activation= 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(11, activation='softmax')\n",
    "])\n",
    "\n",
    "model.load_weights('sudoku2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzles = [os.path.join('puzzles', img) for img in os.listdir('./puzzles/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class SudokuDigitPredictor:\n",
    "\n",
    "    def __init__(self, model, confidence=0.9):\n",
    "        self.model = model\n",
    "        self.confidence = confidence\n",
    "        self.classes = [str(i) for i in range(11)]\n",
    "        \n",
    "    # def preprocess_squares_in_parallel(self, warped_sudoku):\n",
    "    #     with ThreadPoolExecutor(max_workers=4) as executor:  # adjust max_workers as needed\n",
    "    #         squares = list(executor.map(self.preprocess_for_prediction, [warped_sudoku[y_start:y_start + 28, x_start:x_start + 28] for i in range(9) for j in range(9, x_start=i*28, y_start=j*28)]))\n",
    "    #     return squares\n",
    "\n",
    "    def preprocess_for_prediction(self, square):\n",
    "        \"\"\"\n",
    "        Preprocess the cropped square for prediction.\n",
    "        This depends on how your model expects the input. \n",
    "        For example, rescaling, resizing, or reshaping might be necessary.\n",
    "        \"\"\"\n",
    "        # Ensure the square is in grayscale\n",
    "        if len(square.shape) == 3 and square.shape[2] == 3:\n",
    "            square = cv2.cvtColor(square, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        # Remove 10 pixels from all sides\n",
    "        square = square[3:-3, 3:-3]\n",
    "        # Apply binary threshold\n",
    "        _, binary = cv2.threshold(square, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Enhance contrast using histogram equalization\n",
    "        enhanced_binary = cv2.equalizeHist(binary)\n",
    "        \n",
    "        processed_square = cv2.resize(enhanced_binary, (28, 28))  # Resizing\n",
    "        processed_square = np.expand_dims(processed_square, axis=-1)  # Ensure it has a single channel\n",
    "        return processed_square\n",
    "\n",
    "    def predict_digits(self, warped_sudoku):\n",
    "        \"\"\"\n",
    "        Predicts digits for a given warped sudoku grid.\n",
    "        \"\"\"\n",
    "        squares = []\n",
    "        \n",
    "        # Crop the sudoku grid into 81 squares\n",
    "        for i in range(9):\n",
    "            for j in range(9):\n",
    "                x_start, y_start = i * 28, j * 28\n",
    "                square = warped_sudoku[x_start:x_start + 28, y_start:y_start + 28]\n",
    "                squares.append(self.preprocess_for_prediction(square))\n",
    "\n",
    "        # Convert list to numpy array for batch prediction\n",
    "        squares_np = np.stack(squares)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self.model.predict_on_batch(squares_np)\n",
    "\n",
    "        max_confidences = np.amax(predictions, axis=1)\n",
    "        class_indices = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        # Ensure self.classes is a numpy array\n",
    "        class_array = np.array(self.classes)\n",
    "\n",
    "        # Determine where predictions exceed the confidence threshold\n",
    "        above_confidence = max_confidences > self.confidence\n",
    "\n",
    "        # Use boolean indexing to get relevant classes\n",
    "        relevant_classes = class_array[class_indices]\n",
    "\n",
    "        # Where predictions are above the confidence threshold, use predicted class, else '10'\n",
    "        predicted_classes = np.where(above_confidence, relevant_classes, '10').tolist()\n",
    "        \n",
    "        # Convert cell_values to integer-based numpy array, where '10' becomes 0\n",
    "        cell_values_int = np.array([0 if value == '10' else int(value) for value in predicted_classes])\n",
    "\n",
    "        # Reshape the numpy array to the desired 9x9 shape\n",
    "        grid = cell_values_int.reshape(9, 9)\n",
    "        \n",
    "        return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudokuGridHighlighter:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.last_contour = None\n",
    "        self.consistent_detections = 0\n",
    "        self.detection_threshold = 5\n",
    "        self.max_area_detected = 0\n",
    "        self.digit_predictor = SudokuDigitPredictor(model)\n",
    "        self.grid_prediction = None\n",
    "        self.sudoku_solution = None\n",
    "        self.frame_count = 0\n",
    "        self.predict_every_n_frames = 10\n",
    "        self.prev_frame = None\n",
    "\n",
    "    def frame_difference(self, current_frame, prev_frame):\n",
    "        \"\"\"\n",
    "        Compute the difference between current frame and previous frame.\n",
    "        This will be a simple method, but can be made more sophisticated.\n",
    "        \"\"\"\n",
    "        diff = cv2.absdiff(current_frame, prev_frame)\n",
    "        return np.average(diff)\n",
    "    \n",
    "    def preprocess(self, image):\n",
    "        \"\"\"Preprocess the image for contour detection.\"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (3, 3), 6)\n",
    "        return cv2.adaptiveThreshold(blur, 255, 1, 1, 11, 2)\n",
    "\n",
    "    def main_outline(self, contours):\n",
    "        \"\"\"Get the largest 4-sided contour in the image.\"\"\"\n",
    "        max_area = 0\n",
    "        biggest_contour = np.array([])\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            # Adjust the area threshold dynamically\n",
    "            if area > self.max_area_detected * 0.5 and area > max_area:\n",
    "                peri = cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "                \n",
    "                if len(approx) == 4:\n",
    "                    biggest_contour = approx\n",
    "                    max_area = area\n",
    "                        \n",
    "        return biggest_contour, max_area\n",
    "\n",
    "    def get_cropped_region(self, frame, padding=40):\n",
    "        \"\"\"Crops the frame based on the last detected contour and returns the cropped image and its offset.\"\"\"\n",
    "        if self.last_contour is None:\n",
    "            return frame, (0, 0)\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(self.last_contour)\n",
    "        x = max(0, x - padding)\n",
    "        y = max(0, y - padding)\n",
    "        w += 2 * padding\n",
    "        h += 2 * padding\n",
    "\n",
    "        return frame[y:y+h, x:x+w], (x, y)\n",
    "\n",
    "    def order_points(self, pts):\n",
    "        \"\"\"\n",
    "        Order the 4 points in this format: top-left, top-right, bottom-right, bottom-left\n",
    "        \"\"\"\n",
    "        rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "        s = pts.sum(axis=1)\n",
    "        rect[0] = pts[np.argmin(s)]  # top-left will have the smallest sum\n",
    "        rect[2] = pts[np.argmax(s)]  # bottom-right will have the largest sum\n",
    "\n",
    "        diff = np.diff(pts, axis=1)\n",
    "        rect[1] = pts[np.argmin(diff)]  # top-right will have the smallest difference\n",
    "        rect[3] = pts[np.argmax(diff)]  # bottom-left will have the largest difference\n",
    "\n",
    "        return rect\n",
    "\n",
    "    def warp_perspective(self, image, contour):\n",
    "        \"\"\"Warp the perspective to get a top-down view of the image.\"\"\"\n",
    "        \n",
    "        if contour.shape[0] != 4 or contour is None:\n",
    "            return (None, None)\n",
    "\n",
    "        ordered_contour = self.order_points(contour.reshape(4, 2))\n",
    "        src = np.array([\n",
    "            [0, 0],\n",
    "            [252 - 1, 0],\n",
    "            [252 - 1, 252 - 1],\n",
    "            [0, 252 - 1]\n",
    "        ], dtype=\"float32\")\n",
    "\n",
    "        matrix = cv2.getPerspectiveTransform(ordered_contour, src)\n",
    "        warped = cv2.warpPerspective(image, matrix, (252, 252))\n",
    "        \n",
    "        \n",
    "        if warped is None or matrix is None:\n",
    "            return (None, None)\n",
    "        return (warped, matrix)\n",
    "\n",
    "    \n",
    "    def check_sudoku_squares(self, warped_image):\n",
    "        count_valid_squares = 0\n",
    "\n",
    "        for i in range(9):\n",
    "            for j in range(9):\n",
    "                x_start, y_start = i * 28, j * 28\n",
    "                square = warped_image[y_start:y_start + 28, x_start:x_start + 28]\n",
    "                edges = cv2.Canny(square, 50, 150, apertureSize=3)\n",
    "                lines = cv2.HoughLines(edges, 1, np.pi / 180, 15)\n",
    "                \n",
    "                if lines is not None:\n",
    "                    count_valid_squares += 1\n",
    "\n",
    "        return count_valid_squares\n",
    "    \n",
    "    def _solve_sudoku(self, grid):\n",
    "        def is_valid_move(x, y, val, grid):\n",
    "            \"\"\"Check if placing val at grid[x][y] is valid.\"\"\"\n",
    "            \n",
    "            # Check row and column\n",
    "            for i in range(9):\n",
    "                if grid[x][i] == val or grid[i][y] == val:\n",
    "                    return False\n",
    "                    \n",
    "            # Check 3x3 box\n",
    "            startRow, startCol = 3 * (x // 3), 3 * (y // 3)\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    if grid[i + startRow][j + startCol] == val:\n",
    "                        return False\n",
    "                        \n",
    "            return True\n",
    "\n",
    "        def _solve_sudoku_helper(grid_copy):\n",
    "            \"\"\"Helper function for solve_sudoku.\"\"\"\n",
    "            \n",
    "            for x in range(9):\n",
    "                for y in range(9):\n",
    "                    if grid_copy[x][y] == 0:\n",
    "                        for val in range(1, 10):\n",
    "                            if is_valid_move(x, y, val, grid_copy):\n",
    "                                grid_copy[x][y] = val\n",
    "                                if _solve_sudoku_helper(grid_copy):\n",
    "                                    return True\n",
    "                                grid_copy[x][y] = 0\n",
    "                        return False\n",
    "            return True\n",
    "\n",
    "        \"\"\"Fill the grid using backtracking and return a solved copy.\"\"\"\n",
    "            \n",
    "        # Create a deep copy of the original grid\n",
    "        grid_copy = np.copy(grid)\n",
    "        \n",
    "        if _solve_sudoku_helper(grid_copy):\n",
    "            return grid_copy\n",
    "        return None  # Return None if the grid couldn't be solved\n",
    "    \n",
    "    def solve_sudoku_timed(self, grid, timeout=1):\n",
    "        \"\"\"\n",
    "        Attempt to solve the Sudoku with a time limit.\n",
    "        If the Sudoku is solved within the time limit, return the solution.\n",
    "        If not, return None.\n",
    "        \"\"\"\n",
    "        print('solving...')\n",
    "        result = {\"solution\": None}\n",
    "\n",
    "        # Terminate the previous thread if it's still running\n",
    "        if hasattr(self, \"current_thread\") and self.current_thread.is_alive():\n",
    "            # Termination of threads in Python is tricky, but setting a flag to check in the thread's function might work.\n",
    "            # Here's a simple solution that assumes the worker thread periodically checks a flag\n",
    "            self.terminate_thread = True\n",
    "            self.current_thread.join()  # Wait for it to finish (could also be timed)\n",
    "            self.terminate_thread = False\n",
    "\n",
    "        def worker():\n",
    "            if not hasattr(self, \"terminate_thread\") or not self.terminate_thread:\n",
    "                solution = self._solve_sudoku(grid)\n",
    "                result[\"solution\"] = solution\n",
    "\n",
    "        t = threading.Thread(target=worker)\n",
    "        t.start()\n",
    "        t.join(timeout=timeout)  # half a second time limit\n",
    "\n",
    "        if t.is_alive():  # if thread is still running after 0.5 seconds\n",
    "            print(\"couldn't solve in time\")\n",
    "            return None  # or an indication of failure if you prefer\n",
    "\n",
    "        self.current_thread = t  # Save this thread as the current thread\n",
    "        return result[\"solution\"]\n",
    "\n",
    "       \n",
    "    def detect_and_highlight_grid(self, image):\n",
    "        \"\"\"Detects the Sudoku grid and highlights it.\"\"\"\n",
    "        \n",
    "\n",
    "        _original_preprocessed_image = self.preprocess(image)\n",
    "        _original_contours, _ = cv2.findContours(_original_preprocessed_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        _original_biggest_contour, _original_max_area = self.main_outline(_original_contours)\n",
    "        _original_warped, _original_matrix = self.warp_perspective(image, _original_biggest_contour)\n",
    "\n",
    "        cropped_image, (offset_x, offset_y) = self.get_cropped_region(image)\n",
    "        preprocessed_image = self.preprocess(cropped_image)\n",
    "        contours, _ = cv2.findContours(preprocessed_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        biggest_contour, max_area = self.main_outline(contours)\n",
    "        warped, matrix = self.warp_perspective(cropped_image, biggest_contour)\n",
    "        \n",
    "        if warped is None:\n",
    "            self.consistent_detections -= 1\n",
    "            if self.consistent_detections < -3:\n",
    "                self.last_contour = None\n",
    "                self.consistent_detections = 0\n",
    "            return image\n",
    "\n",
    "        valid_squares = self.check_sudoku_squares(warped)\n",
    "        \n",
    "        if valid_squares > 81 * 0.75:\n",
    "            if biggest_contour.size != 0:\n",
    "                biggest_contour += np.array([offset_x, offset_y]).reshape(1, 1, 2)\n",
    "\n",
    "            if max_area > self.max_area_detected:\n",
    "                self.max_area_detected = max_area\n",
    "\n",
    "            cv2.drawContours(image, [biggest_contour], 0, (255, 105, 180), 6)\n",
    "            self.consistent_detections += 1\n",
    "\n",
    "            if self.consistent_detections > self.detection_threshold:\n",
    "                self.last_contour = biggest_contour\n",
    "\n",
    "            # Resizing the warped Sudoku grid to display on the main image\n",
    "            grid_display_size = (100, 100)  # Adjust size as per your requirements\n",
    "            small_grid = cv2.resize(warped, grid_display_size)\n",
    "\n",
    "            # Positioning the warped grid on the bottom right corner of the main image\n",
    "            image[-grid_display_size[1]:, -grid_display_size[0]:] = small_grid\n",
    "            \n",
    "            # Reducing number of predictions\n",
    "            if self.frame_count % self.predict_every_n_frames == 0:\n",
    "                if self.prev_frame is not None:\n",
    "                    diff = self.frame_difference(image, self.prev_frame)\n",
    "                    \n",
    "                    if diff > 12:\n",
    "                        print(f\"Grid shift detected [{diff}]\")\n",
    "                        self.grid_prediction = self.digit_predictor.predict_digits(warped)\n",
    "                        # Use the timed solver here\n",
    "                        solved_grid = self.solve_sudoku_timed(self.grid_prediction)\n",
    "                        if solved_grid is not None:\n",
    "                            self.sudoku_solution = solved_grid\n",
    "                else:\n",
    "                    self.grid_prediction = self.digit_predictor.predict_digits(warped)\n",
    "                    # And here\n",
    "                    solved_grid = self.solve_sudoku_timed(self.grid_prediction)\n",
    "                    if solved_grid is not None:\n",
    "                        self.sudoku_solution = solved_grid\n",
    "\n",
    "        else:\n",
    "            self.consistent_detections -= 1\n",
    "            if self.consistent_detections < -3:\n",
    "                self.last_contour = None\n",
    "                self.consistent_detections = 0\n",
    "        \n",
    "        self.frame_count += 1\n",
    "        self.prev_frame = image.copy()\n",
    "        \n",
    "        if self.sudoku_solution is not None:\n",
    "            return self.overlay(image, _original_warped, _original_matrix)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def overlay_solution_on_image(self, image, grid, original_grid):\n",
    "        \"\"\"\n",
    "        Overlay the solved numbers on the original Sudoku image.\n",
    "\n",
    "        Parameters:\n",
    "        - image: The original Sudoku image.\n",
    "        - grid: The solved Sudoku grid.\n",
    "        - original_grid: The transcribed Sudoku grid from the image.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert grayscale to BGR if image has only one channel\n",
    "        if len(image.shape) == 2 or image.shape[2] == 1:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Dimensions of the image\n",
    "        height, width = image.shape[0:2]\n",
    "\n",
    "        # Dimensions of each cell\n",
    "        cell_width = width // 9\n",
    "        cell_height = height // 9\n",
    "\n",
    "        # Set appropriate font scale and thickness considering the size of the cells\n",
    "        font_scale = min(cell_width, cell_height) / 40  # Adjust the denominator as needed\n",
    "        thickness = math.ceil(font_scale) * 2\n",
    "\n",
    "        for x in range(9):\n",
    "            for y in range(9):\n",
    "                if original_grid[x][y] == 0:  # If the cell was originally empty\n",
    "                    cell_value = str(grid[x][y])\n",
    "\n",
    "                    # Calculate text size\n",
    "                    (text_width, text_height), _ = cv2.getTextSize(cell_value, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)\n",
    "\n",
    "                    # Determine the position to put the text (approximately in the center of the cell)\n",
    "                    pos = (y * cell_width + (cell_width - text_width) // 2, \n",
    "                        x * cell_height + (cell_height + text_height) // 2)\n",
    "\n",
    "                    # Overlay the text on the copied image\n",
    "                    cv2.putText(image, cell_value, pos, cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 105, 180), thickness)\n",
    "        return image    \n",
    "    \n",
    "\n",
    "    def inverse_transform_and_overlay(self, overlayed_image, original_image, matrix):\n",
    "        \"\"\"Inverse transform the overlayed_image and overlay on original image.\"\"\"\n",
    "        inversed = cv2.warpPerspective(overlayed_image, np.linalg.inv(matrix), (original_image.shape[1], original_image.shape[0]))\n",
    "        mask = cv2.warpPerspective(np.ones_like(overlayed_image) * 255, np.linalg.inv(matrix), (original_image.shape[1], original_image.shape[0]))\n",
    "        \n",
    "        # Apply mask to original image to black out the Sudoku area\n",
    "        masked_original = cv2.bitwise_and(original_image, 255 - mask)\n",
    "\n",
    "        # Combine the masked original image with the inversed transformed image\n",
    "        combined = cv2.bitwise_or(masked_original, inversed)\n",
    "\n",
    "        return combined\n",
    "\n",
    "\n",
    "    def overlay(self, image, warped_image, matrix):        \n",
    "        overlayed_image = self.overlay_solution_on_image(warped_image, self.sudoku_solution, self.grid_prediction)\n",
    "        combined_image = self.inverse_transform_and_overlay(overlayed_image, image, matrix)\n",
    "        return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlighter = SudokuGridHighlighter()\n",
    "\n",
    "puzzles = [os.path.join('puzzles', img) for img in os.listdir('./puzzles/')]\n",
    "\n",
    "puzzle = cv2.imread(puzzles[0])\n",
    "\n",
    "highlighted_frame = highlighter.detect_and_highlight_grid(puzzle)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(puzzle)\n",
    "ax[1].imshow(highlighted_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webcam_feed():\n",
    "    highlighter = SudokuGridHighlighter()\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    video_capture.set(cv2.CAP_PROP_FPS, 20)\n",
    "    \n",
    "    # Set resolution\n",
    "    video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 128)\n",
    "    video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 128)\n",
    "\n",
    "    if not video_capture.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        highlighted_frame = highlighter.detect_and_highlight_grid(frame)\n",
    "        cv2.imshow('Webcam Feed - Sudoku Grid Highlighter', highlighted_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    webcam_feed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
